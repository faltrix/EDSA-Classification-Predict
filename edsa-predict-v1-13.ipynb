{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Required Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import f1_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Data\nI am importing both the test and train data so they can undergo the same preprocessing."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\ntest = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[['message']].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Data\nI'm going to check if there are any missing data in any of the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Balance Sentiment Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.sentiment.value_counts())\nsns.countplot(x='sentiment', data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"believe = train[train['sentiment'] == 1]\nno_believe = train[train['sentiment'] == -1]\nneutral = train[train['sentiment'] == 0]\nnews = train[train['sentiment'] == 2]\n\nno_believe_upsampled = resample(no_believe, replace=True,\n                               n_samples=len(believe),\n                               random_state=27)\nneutral_upsampled = resample(neutral, replace=True,\n                               n_samples=len(believe),\n                               random_state=27)\nnews_upsampled = resample(news, replace=True,\n                               n_samples=len(believe),\n                               random_state=27)\n\n# combine majority and upsamples minority\ntrain_upsampled = pd.concat([believe, no_believe_upsampled, \n                            neutral_upsampled, news_upsampled])\nprint(train_upsampled.sentiment.value_counts())\nsns.countplot(x='sentiment', data = train_upsampled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n## Remove noise from both datasets\nI'm going to remove all URL's, email addresses, numbers and punctuation for all messages. I will then transfor all messages to lower case."},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuation_numbers(post):\n    #this function will remove all punction & numbers from a message\n    punc_numbers = string.punctuation + '0123456789'\n    return ''.join([l for l in post if l not in punc_numbers])\n\n    \ndef remove_noise(df):\n    clean_df = df.copy()\n    #Remove URL's\n    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n    subs_url = ' '\n    clean_df['message'] = clean_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n    \n    #Remove emails's\n    pattern_url = r'[A-Z0-9a-z._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,64}'\n    subs_url = ' '\n    clean_df['message'] = clean_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n    \n    # Make Lower case\n    clean_df['message'] = clean_df['message'].str.lower()\n    \n    #Strip out punctuation & numbers\n    clean_df['message'] = clean_df['message'].apply(remove_punctuation_numbers)\n   \n    #Remove Entities\n    #pattern_url = r'\\s([@][\\w_-]+)'\n    #subs_url = ' '\n    #clean_df['message'] = clean_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n\n    #Remove non-standard characters\n    pattern_url = r'[^\\u0000-\\u007F]+'\n    subs_url = ' '\n    clean_df['message'] = clean_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n     \n    #Remove extra spaces\n    pattern_url = r'\\r\\n|\\n|\\r|\\s{2,}'\n    subs_url = ' '\n    clean_df['message'] = clean_df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n     \n    \n    return clean_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[['message']].values)\ntrain = remove_noise(train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[['message']].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = remove_noise (test)\nprint(test.head(15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split training into X & y\nSplit the data in variabel X for features and Y for the label for training data. Also extract the X features for test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['sentiment']\nX = train['message']\ntest_X = test['message']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Vectorize X & test_X"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(strip_accents='ascii',lowercase=True, \n                             analyzer='word', max_df=3000, smooth_idf=True,                             \n                             ngram_range=(1,2),min_df=2, stop_words='english')\nX_vectorized = vectorizer.fit_transform(X)\ntestX_vectorized = vectorizer.transform(test_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split train data into training & validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.05, shuffle=True, random_state = 11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model & evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(penalty='l2', dual=False,tol=0.001, C = 100.0,\n                       fit_intercept=True, intercept_scaling =1,\n                       class_weight=None, random_state=11, \n                       solver='lbfgs', max_iter=1000, multi_class='auto',\n                       verbose=0,warm_start=False, n_jobs=None, \n                        l1_ratio=None)\nlr.fit(X_train,y_train)\nlr_pred = lr.predict(X_val)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check Model Performance\nChecking the performance of model against validation set of the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_val,lr_pred, average='macro')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit Model To Test Data & Evaluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"testlr_pred = lr.predict(testX_vectorized)\ntest['sentiment']=testlr_pred\nprint(test.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating an output csv for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('testsubmission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}